"""
Audio Deepfake Detection - Gradio Frontend
Professional and minimal UI for detecting fake vs real audio
"""

import gradio as gr
import librosa
import numpy as np
import matplotlib.pyplot as plt
from model_loader import get_model_loader
import warnings
warnings.filterwarnings('ignore')

# Initialize model loader
model_loader = get_model_loader()

def extract_mfcc_features(audio_file, n_mfcc=13):
    """Extract MFCC features from audio file"""
    try:
        y, sr = librosa.load(audio_file, sr=None)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
        mfcc_mean = np.mean(mfcc, axis=1)
        mfcc_std = np.std(mfcc, axis=1)
        feature_vector = np.concatenate((mfcc_mean, mfcc_std))
        return feature_vector, y, sr, mfcc
    except Exception as e:
        return None, None, None, None

def create_waveform(y, sr):
    """Create waveform plot"""
    plt.figure(figsize=(10, 3))
    plt.style.use('dark_background')
    librosa.display.waveshow(y, sr=sr, color='#00d4ff', alpha=0.8)
    plt.title('Audio Waveform', fontsize=14, color='white', pad=15)
    plt.xlabel('Time (s)', fontsize=11, color='#aaa')
    plt.ylabel('Amplitude', fontsize=11, color='#aaa')
    plt.tight_layout()
    return plt.gcf()

def create_spectrogram(y, sr):
    """Create spectrogram plot"""
    plt.figure(figsize=(10, 4))
    plt.style.use('dark_background')
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', cmap='viridis')
    plt.colorbar(format='%+2.0f dB')
    plt.title('Spectrogram', fontsize=14, color='white', pad=15)
    plt.xlabel('Time (s)', fontsize=11, color='#aaa')
    plt.ylabel('Frequency (Hz)', fontsize=11, color='#aaa')
    plt.tight_layout()
    return plt.gcf()

def predict_audio(audio_file, model_choice, n_mfcc):
    """Main prediction function"""
    if audio_file is None:
        return "‚ö†Ô∏è Please upload an audio file", None, None, None, None, None
    
    # Extract features
    features, y, sr, mfcc = extract_mfcc_features(audio_file, n_mfcc=n_mfcc)
    
    if features is None:
        return "‚ùå Error processing audio file", None, None, None, None, None
    
    # Make prediction
    if model_choice == "Ensemble (All Models)" and model_loader.has_models():
        prediction, confidence = model_loader.ensemble_predict(features)
    elif model_loader.has_models():
        prediction, confidence = model_loader.predict(features, model_choice)
    else:
        prediction, confidence = model_loader._demo_predict(features)
    
    # Prepare result
    duration = len(y) / sr
    if prediction == 0:
        result = f"""
<div style="background: linear-gradient(135deg, #dc2626 0%, #ef4444 100%); padding: 3rem; border-radius: 20px; text-align: center; color: white; box-shadow: 0 20px 40px rgba(220, 38, 38, 0.4); max-width: 700px; margin: 2rem auto;">
    <h2 style="font-size: 3rem; margin: 0; font-weight: 800;">‚ö†Ô∏è FAKE DETECTED</h2>
    <p style="font-size: 1.8rem; margin-top: 1rem; font-weight: 600;">{confidence*100:.1f}% Confidence</p>
    <p style="margin-top: 1rem; font-size: 1.1rem; opacity: 0.95;">This audio appears to be synthetically generated</p>
</div>
"""
        label = "FAKE"
        color = "#ef4444"
    else:
        result = f"""
<div style="background: linear-gradient(135deg, #059669 0%, #10b981 100%); padding: 3rem; border-radius: 20px; text-align: center; color: white; box-shadow: 0 20px 40px rgba(16, 185, 129, 0.4); max-width: 700px; margin: 2rem auto;">
    <h2 style="font-size: 3rem; margin: 0; font-weight: 800;">‚úÖ REAL AUDIO</h2>
    <p style="font-size: 1.8rem; margin-top: 1rem; font-weight: 600;">{confidence*100:.1f}% Confidence</p>
    <p style="margin-top: 1rem; font-size: 1.1rem; opacity: 0.95;">This audio appears to be authentic</p>
</div>
"""
        label = "REAL"
        color = "#10b981"
    
    # Audio info in a nice card
    info = f"""
<div style="background: #1e293b; padding: 2rem; border-radius: 16px; border: 1px solid #334155; max-width: 700px; margin: 2rem auto;">
    <h3 style="color: #f1f5f9; margin-top: 0; text-align: center; font-size: 1.5rem;">üìä Audio Information</h3>
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin-top: 1.5rem;">
        <div style="text-align: center;">
            <p style="color: #94a3b8; margin: 0; font-size: 0.9rem;">Duration</p>
            <p style="color: #60a5fa; margin: 0.5rem 0 0 0; font-size: 1.5rem; font-weight: 700;">{duration:.2f}s</p>
        </div>
        <div style="text-align: center;">
            <p style="color: #94a3b8; margin: 0; font-size: 0.9rem;">Sample Rate</p>
            <p style="color: #60a5fa; margin: 0.5rem 0 0 0; font-size: 1.5rem; font-weight: 700;">{sr:,} Hz</p>
        </div>
        <div style="text-align: center;">
            <p style="color: #94a3b8; margin: 0; font-size: 0.9rem;">Samples</p>
            <p style="color: #60a5fa; margin: 0.5rem 0 0 0; font-size: 1.5rem; font-weight: 700;">{len(y):,}</p>
        </div>
        <div style="text-align: center;">
            <p style="color: #94a3b8; margin: 0; font-size: 0.9rem;">Prediction</p>
            <p style="color: {color}; margin: 0.5rem 0 0 0; font-size: 1.5rem; font-weight: 700;">{label}</p>
        </div>
    </div>
</div>
"""
    
    # Create visualizations
    waveform_plot = create_waveform(y, sr)
    spectrogram_plot = create_spectrogram(y, sr)
    
    return result, info, waveform_plot, spectrogram_plot, confidence, label

# Custom CSS for professional website-style centered UI with accessibility fixes
custom_css = """
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');

/* Main container - centered website style */
.gradio-container {
    font-family: 'Inter', sans-serif !important;
    background: linear-gradient(135deg, #0a0e1a 0%, #1a1f2e 100%) !important;
    max-width: 1400px !important;
    margin: 0 auto !important;
    padding: 2rem !important;
}

/* Header styling */
.main-header {
    text-align: center;
    margin-bottom: 3rem;
    padding: 2rem 0;
}

h1 {
    background: linear-gradient(135deg, #60a5fa 0%, #a78bfa 50%, #f472b6 100%) !important;
    -webkit-background-clip: text !important;
    background-clip: text !important;
    -webkit-text-fill-color: transparent !important;
    font-size: 3.5rem !important;
    font-weight: 900 !important;
    text-align: center !important;
    margin-bottom: 0.5rem !important;
    letter-spacing: -0.02em !important;
}

/* Subtitle */
.subtitle {
    text-align: center;
    color: #94a3b8;
    font-size: 1.2rem;
    margin-bottom: 2rem;
}

/* Tabs - centered and clean */
.tabs {
    margin: 0 auto;
    max-width: 1200px;
}

.tab-nav button {
    background: transparent !important;
    border: 2px solid transparent !important;
    color: #94a3b8 !important;
    font-size: 1.1rem !important;
    font-weight: 600 !important;
    padding: 1rem 2.5rem !important;
    border-radius: 12px 12px 0 0 !important;
    transition: all 0.3s ease !important;
}

.tab-nav button:hover {
    color: #60a5fa !important;
    background: rgba(59, 130, 246, 0.1) !important;
}

.tab-nav button.selected {
    background: linear-gradient(135deg, #3b82f6 0%, #8b5cf6 100%) !important;
    color: white !important;
    border: none !important;
}

/* Content panels - centered cards */
.gr-panel, .gr-box {
    background: #1e293b !important;
    border-radius: 16px !important;
    border: 1px solid #334155 !important;
    padding: 2rem !important;
    box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.3) !important;
}

/* Center the upload area */
.gr-file-upload {
    margin: 0 auto !important;
    max-width: 600px !important;
}

/* Primary button - centered and large */
.gr-button-primary {
    background: linear-gradient(135deg, #3b82f6 0%, #8b5cf6 100%) !important;
    border: none !important;
    border-radius: 12px !important;
    font-weight: 700 !important;
    font-size: 1.1rem !important;
    padding: 1rem 3rem !important;
    transition: all 0.3s ease !important;
    box-shadow: 0 10px 20px rgba(59, 130, 246, 0.3) !important;
    margin: 1.5rem auto !important;
    display: block !important;
    min-width: 250px !important;
}

.gr-button-primary:hover {
    transform: translateY(-3px) !important;
    box-shadow: 0 15px 30px rgba(59, 130, 246, 0.5) !important;
}

/* Input fields */
.gr-input, .gr-dropdown, .gr-slider {
    background: #334155 !important;
    border: 1px solid #475569 !important;
    border-radius: 10px !important;
    color: #e2e8f0 !important;
    padding: 0.75rem !important;
}

/* Labels */
label {
    color: #cbd5e1 !important;
    font-weight: 600 !important;
    font-size: 1rem !important;
    margin-bottom: 0.5rem !important;
}

/* Result cards - centered */
.gr-markdown {
    max-width: 800px !important;
    margin: 0 auto !important;
    text-align: center !important;
}

.gr-markdown h2 {
    font-size: 2.5rem !important;
    font-weight: 800 !important;
    margin: 2rem 0 !important;
}

.gr-markdown h3 {
    color: #f1f5f9 !important;
    font-size: 1.5rem !important;
    font-weight: 700 !important;
}

/* Plots - larger and centered */
.gr-plot {
    max-width: 1000px !important;
    margin: 2rem auto !important;
}

/* Dataframe */
.gr-dataframe {
    background: #1e293b !important;
    border-radius: 12px !important;
    max-width: 1000px !important;
    margin: 1rem auto !important;
}

/* Row and Column layout - centered */
.gr-row {
    max-width: 1200px !important;
    margin: 0 auto !important;
    gap: 2rem !important;
}

.gr-column {
    background: #1e293b !important;
    border-radius: 16px !important;
    padding: 2rem !important;
}

/* Slider styling */
.gr-slider input[type="range"] {
    accent-color: #3b82f6 !important;
}

/* Audio player */
audio {
    width: 100% !important;
    border-radius: 12px !important;
}

/* Footer */
.footer {
    text-align: center;
    color: #64748b;
    margin-top: 4rem;
    padding-top: 2rem;
    border-top: 1px solid #334155;
}
"""

# Build Gradio Interface - Website Style
with gr.Blocks(css=custom_css, theme=gr.themes.Soft(
    primary_hue="blue",
    secondary_hue="purple",
    neutral_hue="slate",
    font=[gr.themes.GoogleFont("Inter"), "sans-serif"]
)) as app:
    
    # Header Section
    gr.HTML("""
        <div class="main-header">
            <h1>üéôÔ∏è Audio Deepfake Detector</h1>
            <p class="subtitle">Professional AI-Powered Detection of Synthetic Audio</p>
        </div>
    """)
    
    with gr.Tabs() as tabs:
        # Analysis Tab
        with gr.TabItem("üéØ Audio Analysis", id="analysis"):
            gr.Markdown("## Upload and Analyze Audio File")
            
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### Configuration")
                    
                    model_choice = gr.Dropdown(
                        choices=["Random Forest", "XGBoost", "Ensemble (All Models)"],
                        value="Ensemble (All Models)",
                        label="ü§ñ Select Model",
                        info="Ensemble provides best accuracy"
                    )
                    
                    n_mfcc = gr.Slider(
                        minimum=5,
                        maximum=20,
                        value=13,
                        step=1,
                        label="üéµ MFCCs",
                        info="Audio features (default: 13)"
                    )
            
            # Centered upload area
            with gr.Row():
                with gr.Column():
                    audio_input = gr.File(
                        label="üì§ Upload Audio File (WAV, MP3, M4A, FLAC, DAT, OGG, Opus)",
                        file_types=[".wav", ".mp3", ".m4a", ".flac", ".dat", ".ogg", ".opus", ".aac", ".webm"],
                        type="filepath"
                    )
            
            # Centered analyze button
            analyze_btn = gr.Button("üöÄ Analyze Audio", variant="primary", size="lg")
            
            # Results section
            result_output = gr.Markdown(label="Result", visible=True)
            
            with gr.Row():
                info_output = gr.Markdown(label="Audio Details", visible=True)
            
            # Visualizations in a grid
            gr.Markdown("### üìä Visualizations", visible=True)
            with gr.Row():
                waveform_output = gr.Plot(label="Waveform")
                spectrogram_output = gr.Plot(label="Spectrogram")
            
            # Hidden outputs
            confidence_output = gr.Number(visible=False)
            label_output = gr.Text(visible=False)
            
            analyze_btn.click(
                fn=predict_audio,
                inputs=[audio_input, model_choice, n_mfcc],
                outputs=[result_output, info_output, waveform_output, spectrogram_output, confidence_output, label_output]
            )
        
        # Batch Analysis Tab
        with gr.TabItem("üì¶ Batch Processing", id="batch"):
            gr.Markdown("## Analyze Multiple Audio Files")
            gr.Markdown("Upload multiple files to process them all at once")
            
            with gr.Row():
                with gr.Column():
                    batch_files = gr.File(
                        label="üìÅ Upload Multiple Audio Files (WAV, MP3, M4A, FLAC, DAT)",
                        file_count="multiple",
                        file_types=[".wav", ".mp3", ".m4a", ".flac", ".ogg", ".opus", ".dat"]
                    )
            
            with gr.Row():
                with gr.Column():
                    batch_model = gr.Dropdown(
                        choices=["Random Forest", "XGBoost", "Ensemble (All Models)"],
                        value="Ensemble (All Models)",
                        label="ü§ñ Select Model"
                    )
            
            batch_btn = gr.Button("üöÄ Analyze All Files", variant="primary", size="lg")
            
            gr.Markdown("### Results")
            batch_results = gr.Dataframe(
                headers=["Filename", "Prediction", "Confidence", "Duration"],
                label="Analysis Results"
            )
            
            batch_summary = gr.Markdown(label="Summary")
            
            def batch_predict(files, model_choice):
                if not files:
                    return None, "No files uploaded"
                
                results = []
                for file in files:
                    features, y, sr, _ = extract_mfcc_features(file.name, n_mfcc=13)
                    if features is not None:
                        if model_choice == "Ensemble (All Models)" and model_loader.has_models():
                            prediction, confidence = model_loader.ensemble_predict(features)
                        elif model_loader.has_models():
                            prediction, confidence = model_loader.predict(features, model_choice)
                        else:
                            prediction, confidence = model_loader._demo_predict(features)
                        
                        results.append([
                            file.name.split('\\')[-1],
                            "FAKE" if prediction == 0 else "REAL",
                            f"{confidence*100:.1f}%",
                            f"{len(y)/sr:.2f}s"
                        ])
                
                fake_count = sum(1 for r in results if r[1] == "FAKE")
                real_count = sum(1 for r in results if r[1] == "REAL")
                
                summary = f"""
                ### Summary
                - **Total Files:** {len(results)}
                - **Fake Detected:** {fake_count}
                - **Real Detected:** {real_count}
                """
                
                return results, summary
            
            batch_btn.click(
                fn=batch_predict,
                inputs=[batch_files, batch_model],
                outputs=[batch_results, batch_summary]
            )
        
        # Info Tab
        with gr.TabItem("‚ÑπÔ∏è Information", id="info"):
            gr.Markdown("## About This Tool")
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("""
                    ### üéØ What It Does
                    This application uses advanced machine learning to detect AI-generated (deepfake) audio 
                    from authentic recordings with 96% accuracy.
                    
                    ### ü§ñ AI Models
                    - **Random Forest**: 100 decision trees ensemble
                    - **XGBoost**: Gradient boosting algorithm  
                    - **Ensemble**: Combines both for maximum accuracy
                    
                    ### üéµ Technology
                    - **Features**: MFCC (Mel-Frequency Cepstral Coefficients)
                    - **Data Points**: 26 features per audio file
                    - **Processing**: Real-time analysis in under 200ms
                    """)
                
                with gr.Column():
                    gr.Markdown("""
                    ### üìä Performance
                    - **Accuracy**: 96%
                    - **Precision**: 95%
                    - **Recall**: 97%
                    - **F1-Score**: 96%
                    
                    ### üìÅ Training Data
                    - **Training**: 13,185 samples
                    - **Validation**: 12,843 samples
                    - **Testing**: 32,746 samples
                    
                    ### üéß Supported Formats
                    WAV, MP3, M4A, FLAC, OGG, WebM, AAC, Opus, DAT
                    
                    *WAV files recommended for best accuracy*
                    """)
            
            # Footer
            gr.HTML("""
                <div class="footer">
                    <p style="font-size: 0.9rem; color: #64748b;">
                        Built with Gradio ‚Ä¢ Powered by Machine Learning ‚Ä¢ 2025
                    </p>
                </div>
            """)

# Launch the app
if __name__ == "__main__":
    print("=" * 60)
    print("üéôÔ∏è  AUDIO DEEPFAKE DETECTOR - GRADIO")
    print("=" * 60)
    print("\nüöÄ Starting Gradio application...\n")
    
    app.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False,  # Set to False to avoid timeout issues
        show_error=True,
        inbrowser=True  # Auto-open browser
    )
    
    print("\n" + "=" * 60)
    print("‚úÖ App is running!")
    print("=" * 60)
